import cv2
import numpy as np
import openslide
import xml.etree.ElementTree as ET

# image numpy.arrays are [Row, Column, Channel] 

# To use:
# 1. use heatmap() to create heatmap
# 2. use bgr2bgra() to add on alpha channel for merging with original slide
# image
# 3. blend heatmap and WSI using blend_images()
# 4. create image using cv2.imwrite()

def avg_overlaps(pred_arr):

    shape = pred_arr.shape
    arr = np.zeros((shape[0] + 1, shape[1] + 1))

    # Bounds are inclusive
    u_bound_row = shape[0] - 1
    u_bound_col = shape[1] - 1
    l_bound = 0
    
    # Changed np.ndenumerate into traditional for loops for faster performance.
    for row in range(arr.shape[0]):
        for col in range(arr.shape[1]):
            candidates = ((row, col),
                          (row, col - 1),
                          (row - 1, col),
                          (row - 1, col - 1))
            valid = []

            for cand in candidates:
                if (l_bound <= cand[0] <= u_bound_row) and (l_bound <= cand[1] <= u_bound_col):
                    valid.append(pred_arr[cand])

            arr[row, col] = sum(valid) / len(valid)

    return np.array(arr)

def bgr2bgra(image):
    
    b, g, r = cv2.split(image)

    # The np.ones is the alpha channel being added to the heatmap to convert
    # from BGR to BGRA.
    img = cv2.merge((b, g, r, np.ones(b.shape, dtype = heatmap.dtype)))

    return img


def blend_images(slide, heatmap, alpha):

    return cv2.addWeighted(slide, alpha, heatmap, 1 - alpha, 0)

#def draw_tumor_contours(slide, 

def color_heatmap(heatmap, cv2_colormap = cv2.COLORMAP_JET):
#Other colormaps: COLORMAP_ +
#AUTUMN, BONE, JET, WINTER, RAINBOW, OCEAN, SUMMER, SPRING, COOL, HSV, PINK, HOT

    return cv2.applyColorMap(heatmap, cv2_colormap)


def create_mapping(pred_arr, patch_size, level = 0, binary = False, threshold = 0.5):
# pred_mat is a 2D numpy array containing prediction values, ordered so that preserves the
# relative spatial information of patches.
# patch_size is a single int indicating patch dimensions (assumes length =
# width)

    rows, cols = pred_arr.shape
    downsample = 2 ** level
    # Creates empty template that will be colored depending on prediction
    # value. This array is assumed to be equal to the initial slide
    # image in shape.
    mapping = np.zeros((int(rows * patch_size / downsample),
                        int(cols * patch_size / downsample)),
                        dtype = np.uint8)
    
    # One loop iteration fills pixels corresponding to one patch.
    # np.ndenumerate here also substituted with traditional loop for speed.
    for row in range(rows):
        for col in range(cols):
            row_l = int(patch_size * row / downsample)
            row_r = int(patch_size * (row + 1) / downsample)
            col_t = int(patch_size * col / downsample)
            col_b = int(patch_size * (col + 1) / downsample)

            if binary:
                # If binary == T, assign white or black using threshold.
                if x >= threshold:
                    mapping[row_l:row_r, col_t:col_b] = 255
                else:
                    mapping[row_l:row_r, col_t:col_b] = 0

            else:
                # Converts prediction value [0 ~ 1] to grayscale [0 ~ 255]
                mapping[row_l:row_r, col_t:col_b] = round(pred_arr[row, col] * 255)

    return mapping


def heatmap(pred_arr, patch_size, level, overlaps = True, binary = False, threshold = 0.5):
    
    if overlaps:
        arr = avg_overlaps(pred_arr)
        p_size = round(patch_size / 2)

    else:
        arr = pred_arr
        p_size = patch_size

    arr = create_mapping(arr, p_size, level, binary, threshold)

    if not binary:
       arr = color_heatmap(arr)

    return arr

def parseXML(XML_file, downscale = 1):

# Designed to be compatible with cv2.drawContours

# It may seem weird but this is the structure generated by
# cv2.findContours and also the structure that is expected by
# cv2.drawContours

    '''
    An example of output structure
    
    Type(anns): <class 'list'> 
    
    Type(anns[0]): <class 'numpy.ndarray'> 
    [[[   0    0]]
     [[   0 6579]]
     [[2966 6579]]
     [[2966    0]]]
    
    Type(anns[0][0]): <class 'numpy.ndarray'> 
    [[0 0]]
    
    Type(anns[0][0][0]): <class 'numpy.ndarray'> 
    [0 0]
      
    Type(anns[0][0][0][0]): <class 'numpy.int32'> 
    0
    '''

    root = ET.parse(XML_file).getroot()
    anns = [] # List containing all annotation groups

    for node in root.iter('Annotation'):
        group = []
        for subnode in node.iter('Coordinate'):
            group.append(np.array([np.array((round(float(subnode.get('X')) / downscale), 
                                             round(float(subnode.get('Y')) / downscale)), 
                                             dtype = np.int32)], dtype = np.int32))
        group = np.array(group, dtype = np.int32)
        anns.append(group)

    return anns


# Main for unit testing-----------------------------

if __name__ == '__main__':
    
    TEST_IMG_DIR = '/home/jwwoo/pre-camelyon/slide_images/'
    TEST_IMGS = ['b_1.tif', 'b_9.tif', 'b_10.tif']
    # TEST_XMLS = ['b_1.xml', 'b_9.xml', 'b_10.xml']
    PRED_ARR_DIR = ''
    PRED_ARRS = []
    PATCH_SIZE = 304
    LEVEL = 5
    OVERLAPS = True
    BINARY = False
    THRESHOLD = 0.33
    ALPHA = 0.5
    
    '''
    TEST_ARR = np.array([[0. , 0. , 0.3, 0.2],
                         [0.6, 0. , 0.1, 0. ],
                         [1. , 0.4, 0. , 0. ]])
    '''

    for ind, slide in enumerate(TEST_IMGS):
        print('Opening slide...\n')
        slide = openslide.OpenSlide(TEST_IMG_DIR + slide)

        col, row = slide.level_dimensions[LEVEL]
        img = np.array(slide.read_region((0,0), LEVEL, (col, row)))
        
        #TODO replace TEST_ARR with the real thing
        print('Generating heatmap...\n')
        heatmap = heatmap(TEST_ARR, PATCH_SIZE, LEVEL, OVERLAPS, BINARY, THRESHOLD)

        # fakemap is the toy heatmap data that is equal in size to the WSI at level
        # LEVEL. It is used to test the image blending step that happens at
        # blend_images(...).
        '''
        fakemap = cv2.merge((np.ones((row, col), dtype = np.uint8) * 255, # blue
                         np.zeros((row, col), dtype = np.uint8), # green
                         np.zeros((row, col), dtype = np.uint8), # red
                         np.ones((row, col), dtype = np.uint8))) # alpha
        '''

        # print(fakemap.shape, img.shape)
        # print(type(fakemap), type(img))
        if not BINARY:
        
            print('Adding alpha channel to heatmap...\n')
            heatmap = bgr2bgra(heatmap)

            #TODO CHECK THIS
            print('Overlaying slide with heatmap...\n')
            img = blend_images(img, heatmap, ALPHA)

        # print('Processing XML file for tumor region contours...\n')
        # contours = parseXML(TEST_IMG_DIR + TEST_XMLS[0], slide.level_downsamples[LEVEL])
    
        # Draws true contours for tumor regions
        #cv2.drawContours(img, contours, -1, (0,0,0), 3)

    
        cv2.imwrite('final_map.jpg', img)
        print('Done!')
